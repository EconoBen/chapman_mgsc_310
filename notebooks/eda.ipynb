{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at textbook semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, LongformerModel\n",
    "from pandas import DataFrame\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "More about the data [here](https://huggingface.co/datasets/nampdn-ai/tiny-textbooks?row=43).\n",
    "\n",
    "More about huggingface [datasets](https://huggingface.co/docs/datasets/index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e68716edf52499c9320eed647a97f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tiny_textbooks = load_dataset(\"nampdn-ai/tiny-textbooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'source', 's', 'len', 'idx', 'textbook'],\n",
       "        num_rows: 420000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 420000 rows\n",
    "tiny_textbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'An emerging clinical approach to treat substance abuse disorders involves a form of cognitive-behavioral therapy whereby addicts learn to reduce their reactivity to drug-paired stimuli through cue-exposure or extinction training. It is, however, unlikely that extinction training would be consistently effective as a stand- alone treatment in populations that have abused drugs long-term because the key memory systems that are recruited during extinction training are impaired by long-term drug use. There is a critical need to understand mechanisms underlying extinction learning and to establish viable strategies to increase the efficacy of extinction therapies for substance abuse disorders. Key elements of the proposed research plan build on recent advances made in the treatment of conditioned fear and anxiety and other cognitive disorders by pharmacological modulation of glycine, an obligatory co-transmitter at the NMDA glutamate receptor complex. The specific aims of the proposed research in rats and non-human primates are to: 1) elucidate the neurobiological substrates of extinction learning; 2) evaluate selected glycine site partial agonists and glycine transporter-1 (GlyT1) inhibitors as candidate pharmacotherapies to increase the efficacy of extinction training; and 3) determine neurobiological substrates of glycine site modulation of extinction learning. The intravenous cocaine self-administration procedure will be used in the proposed studies because the contingency between drug delivery and behavior is likely paramount for understanding the persistent abuse of drugs in people. Measurement of Fos protein expression (a marker for neuronal activation) and evaluation with anisomycin (an inhibitor of de novo protein synthesis) will be used in rats to investigate the neurobiological substrates of extinction learning following cocaine self-administration training. In addition, the proposed research in rats and non-human primates will specifically investigate the effects of the partial glycine agonist D-cycloserine and selective GlyT1 inhibitors for their ability to accelerate extinction learning and to subsequently reduce cocaine cue reactivity and re-acquisition of cocaine self-administration. Animal research involving pharmacological modulation of learning and memory is well-served by an integrated comparative strategy using appropriately selected laboratory animals. This approach is especially relevant for research involving cognitive enhancing drugs, where non-human primates can serve as a key translational interface for the development of pharmacotherapies. [unreadable] [unreadable] [unreadable]',\n",
       " 'source': 'minipile',\n",
       " 's': 8,\n",
       " 'len': 2646,\n",
       " 'idx': 166352,\n",
       " 'textbook': \"Lesson: Understanding Extinction Training for Substance Abuse Disorders\\n\\nIntroduction:\\nExtinction training is a form of cognitive-behavioral therapy used to treat substance abuse disorders. It involves learning to reduce reactivity to drug-paired stimuli. However, long-term drug use can impair the key memory systems that are recruited during extinction training, making it less effective as a stand-alone treatment for some individuals. In this lesson, we will explore the mechanisms underlying extinction learning and discuss strategies to increase the efficacy of extinction therapies for substance abuse disorders.\\n\\nSection 1: Understanding Extinction Learning\\n\\nTopic 1: What is Extinction Learning?\\nExtinction learning is a process by which an organism learns to stop responding to a previously rewarding stimulus. This occurs through a gradual decrease in the strength of the learned response until it eventually disappears.\\n\\nTopic 2: How does Extinction Learning relate to Substance Abuse Disorders?\\nIn substance abuse disorders, individuals often develop strong associations between drug use and environmental cues. Extinction training aims to weaken these associations, reducing the individual's desire to seek out and use drugs.\\n\\nSection 2: Strategies to Increase the Efficacy of Extinction Therapies for Substance Abuse Disorders\\n\\nTopic 3: Pharmacological Modulation of Glycine\\nRecent research has shown that pharmacological modulation of glycine, an obligatory co-transmitter at the NMDA glutamate receptor complex, can improve extinction learning in animal models. This strategy may help increase the efficacy of extinction therapies for substance abuse disorders.\\n\\nTopic 4: Targeting Specific Memory Systems\\nImpairments in the key memory systems recruited during extinction training can make it less effective for individuals with long-term drug use. By targeting specific memory systems, such as the hippocampus and prefrontal cortex, it may be possible to improve the efficacy of extinction therapies.\\n\\nSection 3: Applying Extinction Training to New Problems\\n\\nTopic 5: Generalizing Extinction Training to Other Disorders\\nThe principles of extinction training can be applied to other disorders, such as anxiety and obsessive-compulsive disorder. By understanding the mechanisms underlying extinction learning, it may be possible to develop new treatments for these and other conditions.\\n\\nConclusion:\\nIn conclusion, understanding the mechanisms underlying extinction learning and developing strategies to increase the efficacy of extinction therapies for substance abuse disorders is crucial for improving treatment outcomes. By targeting specific memory systems and utilizing pharmacological modulation of glycine, it may be possible to enhance the effectiveness of extinction training for individuals with long-term drug use. Additionally, the principles of extinction training can be applied to other disorders, offering potential for the development of new treatments.\\n\\nGlossary:\\n- Extinction learning: A process by which an organism learns to stop responding to a previously rewarding stimulus.\\n- Substance abuse disorders: Conditions characterized by the excessive use of drugs or alcohol leading to significant impairment or distress.\\n- Extinction training: A form of cognitive-behavioral therapy used to treat substance abuse disorders by learning to reduce reactivity to drug-paired stimuli.\\n- NMDA receptor: A type of glutamate receptor found in the brain that plays a role in learning and memory processes.\\n- Glycine: An amino acid that acts as an obligatory co-transmitter at the NMDA receptor complex.\\n- Hippocampus: A region of the brain involved in memory formation and consolidation.\\n- Prefrontal cortex: A region of the brain involved in executive functions such as planning, decision-making, and attention.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_textbooks[\"train\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 495, 17334, 329, 29603, 368, 7897, 4, 11209, 1678, 6, 497, 1168, 6508, 4, 28489, 329, 111, 10, 32656, 6, 1044, 6, 2470, 19, 25330, 1270, 6, 208, 17201, 21115, 835, 9, 14904, 5318, 8, 9370, 647, 1044, 4, 91, 34, 823, 291, 107, 9, 647, 676, 23, 1337, 31944, 5033, 1389, 8, 258, 111, 739, 12, 8056, 758, 7260, 25, 157, 25, 400, 12784, 4, 5337, 9, 464, 36, 7110, 16018, 5206, 6, 210, 2835, 1258, 238, 2375, 12475, 8, 5731, 254, 9, 5, 3919, 4964, 4, 91, 6264, 2752, 708, 11, 5, 19261, 6522, 6, 61, 423, 4173, 566, 5, 275, 11, 5, 138, 4, 83, 704, 8, 11989, 6, 4296, 12095, 1800, 647, 893, 6, 21496, 1626, 1321, 7, 3042, 239, 819, 4, 91, 32829, 327, 39, 2655, 8, 676, 11, 5, 173, 23567, 21640, 19, 451, 25, 41, 2171, 32656, 8, 8298, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tiny_textbooks['train'][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_ids: the numbers representing the tokens in the text.\n",
    "\n",
    "token_type_ids: indicates which sequence a token belongs to if there is more than one sequence.\n",
    "\n",
    "attention_mask: indicates whether a token should be masked or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LongformerModel.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d936d44bc86e4128a4467b359638cd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/420000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def batch_tokenize(batch):\n",
    "    return tokenizer(batch['text'], max_length=4096, padding=True, truncation=True)\n",
    "\n",
    "tokenized_data = tiny_textbooks.map(batch_tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470a7f673b76480c9592afd769d1f094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/420000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Function to get embeddings for a batch\n",
    "def batch_to_embeddings(batch):\n",
    "    input_ids = torch.tensor(batch['input_ids'])\n",
    "    attention_mask = torch.tensor(batch['attention_mask'])\n",
    "\n",
    "    # Run through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Extract and process embeddings\n",
    "    embeddings = torch.mean(outputs.last_hidden_state, dim=1).numpy().tolist()\n",
    "    return {'embeddings': embeddings}\n",
    "\n",
    "embeddings_data = tokenized_data.map(batch_to_embeddings, batched=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
